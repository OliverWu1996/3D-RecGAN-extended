{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recgan",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1_p5tAg_VuGe1RQ3cvwSXOFpAT3ZAs3ti",
      "authorship_tag": "ABX9TyOdRAm7cwCoLTcrEE12wPaB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OliverWu1996/3D-RecGAN-extended/blob/master/recgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jywLT1ycutH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d8a085df-3488-405d-fa39-bc3f0e0f63ab"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/3D-RecGAN-extended-master'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgbwUZaJd0OC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5052ff1-8b11-41c5-9415-51c831cfccf9"
      },
      "source": [
        "cd /content/drive/My Drive/3D-RecGAN-extended-master"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/3D-RecGAN-extended-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58I-RRLyhbaK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7d1de202-2a14-4a0b-c20d-20d6e8c4629e"
      },
      "source": [
        "pwd\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/3D-RecGAN-extended-master'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22iMj8S7j1Or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/3D-RecGAN-extended-master')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXAaOYOMfr4j",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvIUGlyDiAYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1e5f160a-9b0b-49c2-85e0-830316ae7db0"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/3D-RecGAN-extended-master'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0DIxHfLiMJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WxVR3Nlfush",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "93ca5fd5-8afd-4ea2-cc46-f506722ba400"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import tensorflow as tf\n",
        "import tools\n",
        "\n",
        "vox_res64 = 64\n",
        "vox_rex256 = 256\n",
        "batch_size = 4\n",
        "GPU0 = '0'\n",
        "re_train=False\n",
        "\n",
        "#########################\n",
        "config={}\n",
        "config['batch_size']=batch_size\n",
        "config['vox_res_x'] = vox_res64\n",
        "config['vox_res_y'] = vox_rex256\n",
        "config['train_names']=['P1_02828884_bench','P1_03001627_chair','P1_04256520_couch', 'P1_04379243_table']\n",
        "for name in config['train_names']:\n",
        "    config['X_train_'+name] = './Data_sample/'+name+'/train_125_25d_vox256/'\n",
        "    config['Y_train_'+name] = './Data_sample/'+name+'/train_125_3d_vox256/'\n",
        "\n",
        "config['test_names']=['P1_02828884_bench','P1_03001627_chair','P1_04256520_couch', 'P1_04379243_table']\n",
        "for name in config['test_names']:\n",
        "    config['X_test_'+name]= './Data_sample/'+name+'/test_125_25d_vox256/'\n",
        "    config['Y_test_'+name]= './Data_sample/'+name+'/test_125_3d_vox256/'\n",
        "#########################\n",
        "\n",
        "class Network:\n",
        "    def __init__(self, demo_only=False):\n",
        "        if demo_only:\n",
        "            return  # no need to creat folders\n",
        "        self.train_mod_dir = './train_mod/'\n",
        "        self.train_sum_dir = './train_sum/'\n",
        "        self.test_res_dir = './test_res/'\n",
        "        self.test_sum_dir = './test_sum/'\n",
        "\n",
        "        print (\"re_train:\", re_train)\n",
        "        if os.path.exists(self.test_res_dir):\n",
        "            if re_train:\n",
        "                print (\"test_res_dir and files kept!\")\n",
        "            else:\n",
        "                shutil.rmtree(self.test_res_dir)\n",
        "                os.makedirs(self.test_res_dir)\n",
        "                print ('test_res_dir: deleted and then created!')\n",
        "        else:\n",
        "            os.makedirs(self.test_res_dir)\n",
        "            print ('test_res_dir: created!')\n",
        "\n",
        "        if os.path.exists(self.train_mod_dir):\n",
        "            if re_train:\n",
        "                if os.path.exists(self.train_mod_dir + 'model.cptk.data-00000-of-00001'):\n",
        "                    print ('model found! will be reused!')\n",
        "                else:\n",
        "                    print ('model not found! error!')\n",
        "                    exit()\n",
        "            else:\n",
        "                shutil.rmtree(self.train_mod_dir)\n",
        "                os.makedirs(self.train_mod_dir)\n",
        "                print ('train_mod_dir: deleted and then created!')\n",
        "        else:\n",
        "            os.makedirs(self.train_mod_dir)\n",
        "            print ('train_mod_dir: created!')\n",
        "\n",
        "        if os.path.exists(self.train_sum_dir):\n",
        "            if re_train:\n",
        "                print (\"train_sum_dir and files kept!\")\n",
        "            else:\n",
        "                shutil.rmtree(self.train_sum_dir)\n",
        "                os.makedirs(self.train_sum_dir)\n",
        "                print ('train_sum_dir: deleted and then created!')\n",
        "        else:\n",
        "            os.makedirs(self.train_sum_dir)\n",
        "            print ('train_sum_dir: created!')\n",
        "\n",
        "        if os.path.exists(self.test_sum_dir):\n",
        "            if re_train:\n",
        "                print (\"test_sum_dir and files kept!\")\n",
        "            else:\n",
        "                shutil.rmtree(self.test_sum_dir)\n",
        "                os.makedirs(self.test_sum_dir)\n",
        "                print ('test_sum_dir: deleted and then created!')\n",
        "        else:\n",
        "            os.makedirs(self.test_sum_dir)\n",
        "            print ('test_sum_dir: created!')\n",
        "\n",
        "    def aeu(self, X):\n",
        "        with tf.device('/gpu:'+GPU0):\n",
        "            X = tf.reshape(X,[-1, vox_res64,vox_res64,vox_res64,1])\n",
        "            c_e = [1,64,128,256,512]\n",
        "            s_e = [0,1 , 1, 1, 1]\n",
        "            layers_e = []\n",
        "            layers_e.append(X)\n",
        "            for i in range(1,5,1):\n",
        "                layer = tools.Ops.conv3d(layers_e[-1],k=4,out_c=c_e[i],str=s_e[i],name='e'+str(i))\n",
        "                layer = tools.Ops.maxpool3d(tools.Ops.xxlu(layer, label='lrelu'), k=2,s=2,pad='SAME')\n",
        "                layers_e.append(layer)\n",
        "\n",
        "            ### fc\n",
        "            [_, d1, d2, d3, cc] = layers_e[-1].get_shape()\n",
        "            d1=int(d1); d2=int(d2); d3=int(d3); cc=int(cc)\n",
        "            lfc = tf.reshape(layers_e[-1],[-1, int(d1)*int(d2)*int(d3)*int(cc)])\n",
        "            lfc = tools.Ops.xxlu(tools.Ops.fc(lfc, out_d=2000,name='fc1'), label='relu')\n",
        "\n",
        "        with tf.device('/gpu:'+GPU0):\n",
        "            lfc = tools.Ops.xxlu(tools.Ops.fc(lfc,out_d=d1*d2*d3*cc, name='fc2'), label='relu')\n",
        "            lfc = tf.reshape(lfc, [-1, d1,d2,d3,cc])\n",
        "\n",
        "            c_d = [0,256,128,64,16,8]\n",
        "            s_d = [0,2,2,2,2,2]\n",
        "            layers_d = []\n",
        "            layers_d.append(lfc)\n",
        "            for j in range(1,6,1):\n",
        "                u_net = True\n",
        "                if u_net:\n",
        "                    layer = tf.concat([layers_d[-1], layers_e[-j]],axis=4)\n",
        "                    layer = tools.Ops.deconv3d(layer, k=4,out_c=c_d[j], str=s_d[j],name='d'+str(len(layers_d)))\n",
        "                else:\n",
        "                    layer = tools.Ops.deconv3d(layers_d[-1],k=4,out_c=c_d[j],str=s_d[j],name='d'+str(len(layers_d)))\n",
        "\n",
        "                layer = tools.Ops.xxlu(layer, label='relu')\n",
        "                layers_d.append(layer)\n",
        "            ###\n",
        "            layer = tools.Ops.deconv3d(layers_d[-1],k=4,out_c=1,str=2,name='dlast')\n",
        "            ###\n",
        "            Y_sig = tf.nn.sigmoid(layer)\n",
        "            Y_sig_modi = tf.maximum(Y_sig,0.01)\n",
        "\n",
        "        return Y_sig, Y_sig_modi\n",
        "\n",
        "    def dis(self, X, Y):\n",
        "        with tf.device('/gpu:'+GPU0):\n",
        "            X = tf.reshape(X,[-1, vox_res64, vox_res64, vox_res64,1])\n",
        "            X = tf.reshape(X, [-1, vox_rex256, vox_rex256, 4, 1])\n",
        "            Y = tf.reshape(Y,[-1, vox_rex256, vox_rex256,vox_rex256,1])\n",
        "            Y = tf.concat([X, Y],axis=3)\n",
        "\n",
        "            c_d = [1,8,16,32,64,128,256]\n",
        "            s_d = [0,2,2,2,2,2,2]\n",
        "            layers_d =[]\n",
        "            layers_d.append(Y)\n",
        "            for i in range(1,7,1):\n",
        "                layer = tools.Ops.conv3d(layers_d[-1],k=4,out_c=c_d[i],str=s_d[i],name='d'+str(i))\n",
        "                if i!=6:\n",
        "                    layer = tools.Ops.xxlu(layer, label='lrelu')\n",
        "                layers_d.append(layer)\n",
        "            [_, d1, d2, d3, cc] = layers_d[-1].get_shape()\n",
        "            d1 = int(d1); d2 = int(d2); d3 = int(d3); cc = int(cc)\n",
        "            y = tf.reshape(layers_d[-1],[-1,d1*d2*d3*cc])\n",
        "        return tf.nn.sigmoid(y)\n",
        "\n",
        "    def build_graph(self):\n",
        "        self.X = tf.placeholder(shape=[None, vox_res64, vox_res64, vox_res64, 1], dtype=tf.float32)\n",
        "        self.Y = tf.placeholder(shape=[None, vox_rex256, vox_rex256, vox_rex256, 1], dtype=tf.float32)\n",
        "\n",
        "        with tf.variable_scope('aeu'):\n",
        "            self.Y_pred, self.Y_pred_modi = self.aeu(self.X)\n",
        "        with tf.variable_scope('dis'):\n",
        "            self.XY_real_pair = self.dis(self.X, self.Y)\n",
        "        with tf.variable_scope('dis',reuse=True):\n",
        "            self.XY_fake_pair = self.dis(self.X, self.Y_pred)\n",
        "\n",
        "        with tf.device('/gpu:'+GPU0):\n",
        "            ################################ ae loss\n",
        "            Y_ = tf.reshape(self.Y, shape=[-1, vox_rex256**3])\n",
        "            Y_pred_modi_ = tf.reshape(self.Y_pred_modi, shape=[-1, vox_rex256**3])\n",
        "            w = 0.85\n",
        "            self.aeu_loss = tf.reduce_mean(-tf.reduce_mean(w * Y_ * tf.log(Y_pred_modi_ + 1e-8), reduction_indices=[1]) -\n",
        "                                       tf.reduce_mean((1 - w) * (1 - Y_) * tf.log(1 - Y_pred_modi_ + 1e-8), reduction_indices=[1]))\n",
        "            sum_aeu_loss = tf.summary.scalar('aeu_loss', self.aeu_loss)\n",
        "\n",
        "            ################################ wgan loss\n",
        "            self.gan_g_loss = -tf.reduce_mean(self.XY_fake_pair)\n",
        "            self.gan_d_loss_no_gp = tf.reduce_mean(self.XY_fake_pair) - tf.reduce_mean(self.XY_real_pair)\n",
        "            sum_gan_g_loss = tf.summary.scalar('gan_g_loss', self.gan_g_loss)\n",
        "            sum_gan_d_loss_no_gp = tf.summary.scalar('gan_d_loss_no_gp', self.gan_d_loss_no_gp)\n",
        "            alpha = tf.random_uniform(shape=[tf.shape(self.X)[0], vox_rex256 ** 3], minval=0.0, maxval=1.0)\n",
        "\n",
        "            Y_pred_ = tf.reshape(self.Y_pred, shape=[-1, vox_rex256 ** 3])\n",
        "            differences_ = Y_pred_ - Y_\n",
        "            interpolates = Y_ + alpha*differences_\n",
        "            with tf.variable_scope('dis',reuse=True):\n",
        "                XY_fake_intep = self.dis(self.X, interpolates)\n",
        "            gradients = tf.gradients(XY_fake_intep, [interpolates])[0]\n",
        "            slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
        "            gradient_penalty = tf.reduce_mean((slopes - 1.0) ** 2)\n",
        "            self.gan_d_loss_gp = self.gan_d_loss_no_gp + 10 * gradient_penalty\n",
        "            sum_gan_d_loss_gp = tf.summary.scalar('gan_d_loss_gp', self.gan_d_loss_gp)\n",
        "\n",
        "            #################################  ae + gan loss\n",
        "            gan_g_w = 20\n",
        "            aeu_w = 100 - gan_g_w\n",
        "            self.aeu_gan_g_loss = aeu_w*self.aeu_loss + gan_g_w*self.gan_g_loss\n",
        "\n",
        "        with tf.device('/gpu:'+GPU0):\n",
        "            aeu_var = [var for var in tf.trainable_variables() if var.name.startswith('aeu')]\n",
        "            dis_var = [var for var in tf.trainable_variables() if var.name.startswith('dis')]\n",
        "            self.aeu_g_optim = tf.train.AdamOptimizer(learning_rate=0.0001, beta1=0.9, beta2=0.999, epsilon=1e-8).\\\n",
        "                            minimize(self.aeu_gan_g_loss, var_list=aeu_var)\n",
        "            self.dis_optim = tf.train.AdamOptimizer(learning_rate=0.00005, beta1=0.9, beta2=0.999, epsilon=1e-8).\\\n",
        "                            minimize(self.gan_d_loss_gp,var_list=dis_var)\n",
        "\n",
        "        print (tools.Ops.variable_count())\n",
        "        self.sum_merged = tf.summary.merge_all()\n",
        "        self.saver = tf.train.Saver(max_to_keep=1)\n",
        "        config = tf.ConfigProto(allow_soft_placement=True)\n",
        "        config.gpu_options.visible_device_list = GPU0\n",
        "\n",
        "        self.sess = tf.Session(config=config)\n",
        "        self.sum_writer_train = tf.summary.FileWriter(self.train_sum_dir, self.sess.graph)\n",
        "        self.sum_write_test = tf.summary.FileWriter(self.test_sum_dir)\n",
        "\n",
        "        path = self.train_mod_dir\n",
        "        #path = './Model_released/'   # to retrain our released model\n",
        "        if os.path.isfile(path + 'model.cptk.data-00000-of-00001'):\n",
        "            print ('restoring saved model')\n",
        "            self.saver.restore(self.sess, path + 'model.cptk')\n",
        "        else:\n",
        "            print ('initilizing model')\n",
        "            self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        return 0\n",
        "\n",
        "    def train(self, data):\n",
        "        for epoch in range(10):\n",
        "            data.shuffle_X_Y_files(label='train')\n",
        "            total_train_batch_num = data.total_train_batch_num\n",
        "            print ('total_train_batch_num:', total_train_batch_num)\n",
        "            for i in range(total_train_batch_num):\n",
        "\n",
        "                #################### training\n",
        "                X_train_batch, Y_train_batch = data.queue_train.get()\n",
        "                self.sess.run(self.dis_optim, feed_dict={self.X:X_train_batch, self.Y:Y_train_batch})\n",
        "                self.sess.run(self.aeu_g_optim, feed_dict={self.X:X_train_batch, self.Y:Y_train_batch})\n",
        "\n",
        "                aeu_loss_c, gan_g_loss_c, gan_d_loss_no_gp_c, gan_d_loss_gp_c, sum_train = self.sess.run(\n",
        "                [self.aeu_loss, self.gan_g_loss, self.gan_d_loss_no_gp, self.gan_d_loss_gp, self.sum_merged],\n",
        "                feed_dict={self.X:X_train_batch, self.Y:Y_train_batch})\n",
        "\n",
        "                if i%200==0:\n",
        "                    self.sum_writer_train.add_summary(sum_train, epoch * total_train_batch_num + i)\n",
        "                print ('ep:',epoch,'i:',i, 'train aeu loss:',aeu_loss_c, 'gan g loss:',gan_g_loss_c,\n",
        "                       'gan d loss no gp:',gan_d_loss_no_gp_c,'gan d loss gp:', gan_d_loss_gp_c)\n",
        "\n",
        "                #################### testing\n",
        "                if i%600==0:\n",
        "                    X_test_batch, Y_test_batch = data.load_X_Y_voxel_grids_test_next_batch()\n",
        "\n",
        "                    aeu_loss_t, gan_g_loss_t, gan_d_loss_no_gp_t, gan_d_loss_gp_t, Y_pred_t, sum_test = self.sess.run(\n",
        "                    [self.aeu_loss, self.gan_g_loss, self.gan_d_loss_no_gp, self.gan_d_loss_gp, self.Y_pred, self.sum_merged],\n",
        "                    feed_dict={self.X:X_test_batch, self.Y:Y_test_batch})\n",
        "\n",
        "                    X_test_batch=X_test_batch.astype(np.int8)\n",
        "                    Y_pred_t=Y_pred_t.astype(np.float16)\n",
        "                    Y_test_batch=Y_test_batch.astype(np.int8)\n",
        "                    to_save = {'X_test':X_test_batch, 'Y_test_pred':Y_pred_t, 'Y_test_true':Y_test_batch}\n",
        "\n",
        "                    scipy.io.savemat(self.test_res_dir+'X_Y_pred_'+str(epoch).zfill(2)+'_'+str(i).zfill(5)+'.mat',\n",
        "                    to_save, do_compression=True)\n",
        "\n",
        "                    self.sum_write_test.add_summary(sum_test, epoch*total_train_batch_num+i)\n",
        "                    print ('ep:',epoch, 'i:', i, 'test aeu loss:', aeu_loss_t,'gan g loss:', gan_g_loss_t,\n",
        "                           'gan d loss no gp:',gan_d_loss_no_gp_t,'gan d loss gp:',gan_d_loss_gp_t)\n",
        "\n",
        "                #### model saving\n",
        "                if i%600 == 0 and i > 0:\n",
        "                    self.saver.save(self.sess, save_path=self.train_mod_dir + 'model.cptk')\n",
        "                    print ('ep:', epoch, 'i:', i, 'model saved!')\n",
        "\n",
        "        data.stop_queue=True\n",
        "\n",
        "#########################\n",
        "if __name__ == '__main__':\n",
        "    data = tools.Data(config)\n",
        "    data.daemon = True\n",
        "    data.start()\n",
        "    net = Network()\n",
        "    net.build_graph()\n",
        "    net.train(data)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9 (default, Jul 17 2020, 12:50:27) \n",
            "[GCC 8.4.0]\n",
            "3.6.9 (default, Jul 17 2020, 12:50:27) \n",
            "[GCC 8.4.0]\n",
            "X_train_files: 16\n",
            "X_test_files: 16\n",
            "re_train: False\n",
            "test_res_dir: deleted and then created!\n",
            "train_mod_dir: deleted and then created!\n",
            "train_sum_dir: deleted and then created!\n",
            "test_sum_dir: deleted and then created!\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/3D-RecGAN-extended-master/tools.py:306: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/3D-RecGAN-extended-master/tools.py:265: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/3D-RecGAN-extended-master/tools.py:270: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "167077217\n",
            "initilizing model\n",
            "total_train_batch_num: 4\n",
            "ep: 0 i: 0 train aeu loss: 0.1072225 gan g loss: -0.49994546 gan d loss no gp: -4.976988e-05 gan d loss gp: 1.2497401\n",
            "ep: 0 i: 0 test aeu loss: 0.12693042 gan g loss: -0.49994534 gan d loss no gp: -4.0352345e-05 gan d loss gp: 1.2823277\n",
            "ep: 0 i: 1 train aeu loss: 0.12685254 gan g loss: -0.49992627 gan d loss no gp: -5.5134296e-05 gan d loss gp: 0.4354509\n",
            "shuffle\n",
            "ep: 0 i: 2 train aeu loss: 0.12052234 gan g loss: -0.4999063 gan d loss no gp: -7.891655e-05 gan d loss gp: 0.031921\n",
            "ep: 0 i: 3 train aeu loss: 0.1195589 gan g loss: -0.49988708 gan d loss no gp: -9.918213e-05 gan d loss gp: 0.09311944\n",
            "total_train_batch_num: 4\n",
            "ep: 1 i: 0 train aeu loss: 0.12047284 gan g loss: -0.49987108 gan d loss no gp: -0.00010764599 gan d loss gp: 0.41001955\n",
            "ep: 1 i: 0 test aeu loss: 0.12867877 gan g loss: -0.49987087 gan d loss no gp: -9.790063e-05 gan d loss gp: 0.3839396\n",
            "ep: 1 i: 1 train aeu loss: 0.12018498 gan g loss: -0.49986172 gan d loss no gp: -0.00011333823 gan d loss gp: 0.58534515\n",
            "ep: 1 i: 2 train aeu loss: 0.1273203 gan g loss: -0.49985808 gan d loss no gp: -0.000115692616 gan d loss gp: 0.5331239\n",
            "ep: 1 i: 3 train aeu loss: 0.1284152 gan g loss: -0.4998579 gan d loss no gp: -0.00010481477 gan d loss gp: 0.34423807\n",
            "total_train_batch_num: 4\n",
            "ep: 2 i: 0 train aeu loss: 0.11921824 gan g loss: -0.49986047 gan d loss no gp: -0.000116467476 gan d loss gp: 0.17564087\n",
            "ep: 2 i: 0 test aeu loss: 0.12451501 gan g loss: -0.4998601 gan d loss no gp: -0.00010070205 gan d loss gp: 0.16884348\n",
            "ep: 2 i: 1 train aeu loss: 0.11698859 gan g loss: -0.4998644 gan d loss no gp: -0.00010976195 gan d loss gp: 0.041305177\n",
            "ep: 2 i: 2 train aeu loss: 0.12261984 gan g loss: -0.4998687 gan d loss no gp: -0.00010317564 gan d loss gp: 0.00016869474\n",
            "ep: 2 i: 3 train aeu loss: 0.12753484 gan g loss: -0.4998724 gan d loss no gp: -9.223819e-05 gan d loss gp: 0.02623016\n",
            "total_train_batch_num: 4\n",
            "ep: 3 i: 0 train aeu loss: 0.124703735 gan g loss: -0.49987483 gan d loss no gp: -9.226799e-05 gan d loss gp: 0.08898971\n",
            "ep: 3 i: 0 test aeu loss: 0.1313451 gan g loss: -0.49987477 gan d loss no gp: -9.2983246e-05 gan d loss gp: 0.08543885\n",
            "ep: 3 i: 1 train aeu loss: 0.12034821 gan g loss: -0.49987593 gan d loss no gp: -9.468198e-05 gan d loss gp: 0.13845976\n",
            "ep: 3 i: 2 train aeu loss: 0.114508554 gan g loss: -0.49987572 gan d loss no gp: -0.00010076165 gan d loss gp: 0.15700945\n",
            "ep: 3 i: 3 train aeu loss: 0.12323885 gan g loss: -0.4998738 gan d loss no gp: -9.807944e-05 gan d loss gp: 0.17050722\n",
            "total_train_batch_num: 4\n",
            "ep: 4 i: 0 train aeu loss: 0.117363855 gan g loss: -0.4998706 gan d loss no gp: -9.8496675e-05 gan d loss gp: 0.124241024\n",
            "ep: 4 i: 0 test aeu loss: 0.13704044 gan g loss: -0.49987054 gan d loss no gp: -9.2208385e-05 gan d loss gp: 0.13504347\n",
            "ep: 4 i: 1 train aeu loss: 0.11895065 gan g loss: -0.4998664 gan d loss no gp: -0.00010898709 gan d loss gp: 0.076036945\n",
            "ep: 4 i: 2 train aeu loss: 0.12734696 gan g loss: -0.49986094 gan d loss no gp: -0.00010442734 gan d loss gp: 0.040805425\n",
            "ep: 4 i: 3 train aeu loss: 0.12241371 gan g loss: -0.49985504 gan d loss no gp: -0.00011664629 gan d loss gp: 0.0077352608\n",
            "total_train_batch_num: 4\n",
            "ep: 5 i: 0 train aeu loss: 0.12486388 gan g loss: -0.49984893 gan d loss no gp: -0.00012102723 gan d loss gp: 0.00068774284\n",
            "ep: 5 i: 0 test aeu loss: 0.13497716 gan g loss: -0.4998487 gan d loss no gp: -0.00011381507 gan d loss gp: 0.00051467697\n",
            "ep: 5 i: 1 train aeu loss: 0.11814879 gan g loss: -0.49984288 gan d loss no gp: -0.0001322329 gan d loss gp: 0.018186122\n",
            "ep: 5 i: 2 train aeu loss: 0.12121383 gan g loss: -0.4998378 gan d loss no gp: -0.00013440847 gan d loss gp: 0.045227703\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}